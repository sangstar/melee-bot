{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["key = ''"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-08-10T20:03:55.824372Z","iopub.execute_input":"2023-08-10T20:03:55.824794Z","iopub.status.idle":"2023-08-10T20:03:55.830509Z","shell.execute_reply.started":"2023-08-10T20:03:55.824764Z","shell.execute_reply":"2023-08-10T20:03:55.829246Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["!pip3 install -U langchain openai pandas\n","import langchain\n","import openai\n","from langchain.chat_models import ChatOpenAI\n","from langchain.llms import OpenAI\n","from langchain.prompts import ChatPromptTemplate, PromptTemplate\n","from langchain.callbacks import get_openai_callback "],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:03:55.832205Z","iopub.execute_input":"2023-08-10T20:03:55.832536Z","iopub.status.idle":"2023-08-10T20:04:10.666725Z","shell.execute_reply.started":"2023-08-10T20:03:55.832508Z","shell.execute_reply":"2023-08-10T20:04:10.665584Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import os\n","base_dir = \"/kaggle/input/melee-characters/\"\n","\n","def parse_cost(cost):\n","    return float(str(cost).split(\"\\n\")[-1].split(\" \")[-1].replace(\"$\",\"\"))\n","\n","def fetch_data(character):\n","    file_path = base_dir + f\"{character}.txt\"\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","    return text\n","\n","def get_chunks(text_str, num_chunks):\n","    chunk_size = len(text_str) // num_chunks\n","    chunks = [text_str[i:i + chunk_size] for i in range(0, len(text_str), chunk_size)]\n","    return chunks\n","\n","def get_character_data(character, num_chunks):\n","    text = fetch_data(character)\n","    chunks = get_chunks(text, num_chunks)\n","    return chunks[:-1]\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.670050Z","iopub.execute_input":"2023-08-10T20:04:10.670583Z","iopub.status.idle":"2023-08-10T20:04:10.680467Z","shell.execute_reply.started":"2023-08-10T20:04:10.670532Z","shell.execute_reply":"2023-08-10T20:04:10.679366Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["characters = os.listdir(base_dir)\n","characters = [x.replace('.txt','') for x in characters]"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.684529Z","iopub.execute_input":"2023-08-10T20:04:10.684959Z","iopub.status.idle":"2023-08-10T20:04:10.707055Z","shell.execute_reply.started":"2023-08-10T20:04:10.684918Z","shell.execute_reply":"2023-08-10T20:04:10.705791Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["model_gpt35 = \"gpt-3.5-turbo-16k\"\n","chatgpt = ChatOpenAI(temperature = 0.7, model = model_gpt35, openai_api_key = key)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.708535Z","iopub.execute_input":"2023-08-10T20:04:10.708871Z","iopub.status.idle":"2023-08-10T20:04:10.714963Z","shell.execute_reply.started":"2023-08-10T20:04:10.708842Z","shell.execute_reply":"2023-08-10T20:04:10.713994Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","\n","# Less varied FAQ's if smaller chunk size as ChatGPT has a more constrained possibility\n","# of FAQs to make. Try to force smaller while still showing randomness\n","\n","## Normally: \n","# mean = 3\n","# std = 3.5\n","# min = 2\n","# max = 50\n","\n","## For fox:\n","# mean = 45\n","# std_dev = 3\n","# min_val = 35\n","\n","def sample_chunk_size(num_samples, mean, std_dev, min_val, max_val):\n","    mean = mean\n","    std_deviation = std_dev  # Adjust this value based on your desired standard deviation\n","    min_value = min_val\n","    max_value = max_val\n","    num_samples = num_samples  # Adjust the number of samples as needed\n","\n","    samples = np.random.normal(mean, std_deviation, num_samples)\n","    samples = np.clip(samples, min_value, max_value)\n","    samples = [int(x) for x in samples]\n","\n","    return samples"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.715942Z","iopub.execute_input":"2023-08-10T20:04:10.716251Z","iopub.status.idle":"2023-08-10T20:04:10.732053Z","shell.execute_reply.started":"2023-08-10T20:04:10.716222Z","shell.execute_reply":"2023-08-10T20:04:10.730060Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["starting_prompt=\"\"\"\n","You are a helpful assistant that takes user-written guides on playable characters from Super Smash Brothers Melee for the Nintendo Gamecube and creates questions and answers based on the guide.\n","As you are producing question and answer pairs for competitive players, please try to ensure the questions and answers are not overly simplistic.\"\"\""],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.733724Z","iopub.execute_input":"2023-08-10T20:04:10.734192Z","iopub.status.idle":"2023-08-10T20:04:10.745496Z","shell.execute_reply.started":"2023-08-10T20:04:10.734149Z","shell.execute_reply":"2023-08-10T20:04:10.744674Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def enrich_prompt(starting_prompt):\n","    starting_prompt += \"\\n\"\n","    technical_decider = np.random.choice([0,1])\n","    if technical_decider == 1:\n","        print('Question made more technical')\n","        starting_prompt += \"Questions should be as technical as possible.\\n\"\n","        \n","    length_decider = np.random.choice([0,1,2])\n","    if length_decider == 1:\n","        print('Answer lengthy')\n","        starting_prompt += \"Answers should be lengthy.\\n\"\n","    if length_decider == 0:\n","        print('Answer concise')\n","        starting_prompt += \"Answers should be concise.\\n\"\n","    else:\n","        starting_prompt += \"\"\n","        \n","    starting_prompt+=\"\"\"\n","Do not mention the guide itself in any way. Split the question answer pairs by two newlines.\n","\n","#Guide#: \n","{guide}\n","\n","#Generated questions and answers#:\n","    \"\"\"\n","    \n","    return starting_prompt\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.746640Z","iopub.execute_input":"2023-08-10T20:04:10.747058Z","iopub.status.idle":"2023-08-10T20:04:10.760248Z","shell.execute_reply.started":"2023-08-10T20:04:10.747018Z","shell.execute_reply":"2023-08-10T20:04:10.759372Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["print(enrich_prompt(starting_prompt))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.761918Z","iopub.execute_input":"2023-08-10T20:04:10.762339Z","iopub.status.idle":"2023-08-10T20:04:10.781005Z","shell.execute_reply.started":"2023-08-10T20:04:10.762300Z","shell.execute_reply":"2023-08-10T20:04:10.780036Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["from openai import InvalidRequestError\n","from openai.error import RateLimitError\n","import logging\n","import io\n","from langchain.llms.base import logger"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.784850Z","iopub.execute_input":"2023-08-10T20:04:10.785228Z","iopub.status.idle":"2023-08-10T20:04:10.792985Z","shell.execute_reply.started":"2023-08-10T20:04:10.785196Z","shell.execute_reply":"2023-08-10T20:04:10.791697Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["results = []"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:04:10.794783Z","iopub.execute_input":"2023-08-10T20:04:10.795204Z","iopub.status.idle":"2023-08-10T20:04:10.806461Z","shell.execute_reply.started":"2023-08-10T20:04:10.795165Z","shell.execute_reply":"2023-08-10T20:04:10.805572Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["costs = 0\n","its = 20\n","\n","for character in characters:\n","    print('Character: ',character)\n","    if character == 'fox': ## By far the most data, so smaller. chunks will max context length\n","        print('Doing fox. Need to use larger chunk size with mean ', 30)\n","        chunk_sizes = sample_chunk_size(num_samples = its, mean = 30, std_dev = 3, min_val = 20, max_val = 50)\n","    else:\n","        print('Using chunk size with mean ', 12)\n","        chunk_sizes = sample_chunk_size(num_samples = its, mean = 12, std_dev = 5, min_val = 2, max_val = 50)\n","    for i in chunk_sizes:\n","        print('New it')\n","        num_chunks = i\n","        print('num chunks:',num_chunks)\n","        text = get_character_data(character, num_chunks)\n","        for chunk in text:\n","            try:\n","                log_capture_buffer = io.StringIO()\n","                with get_openai_callback() as cost:\n","                    template = ChatPromptTemplate.from_messages([\n","                        (\"system\", enrich_prompt(starting_prompt)),\n","                    ])\n","                    response = chatgpt(template.format_messages(guide = chunk))\n","                    for qa in response.content.split(\"\\n\\n\"):\n","                        results.append({\"character\":character, \"qa\":qa})\n","                    costs += parse_cost(cost)\n","            except InvalidRequestError as invalidrequest:\n","                print(invalidrequest)\n","            except Exception as err:\n","                print(err)\n","            finally:\n","                log_handler = logging.StreamHandler(log_capture_buffer)\n","                logger.addHandler(log_handler)\n","                log_handler.flush()\n","                captured_logs = log_capture_buffer.getvalue()\n","                if \"RateLimitError\" in captured_logs:\n","                    print('Sleeping for rate limit error')\n","                    time.sleep(61)\n","                    log_handler = logging.StreamHandler(log_capture_buffer)\n","\n","                # Remove the log handler to prevent duplicate logs\n","                logger.removeHandler(log_handler)\n","\n","    print(f'Billed so far: {costs}')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:10:29.987162Z","iopub.execute_input":"2023-08-10T20:10:29.988509Z","iopub.status.idle":"2023-08-10T20:10:32.748390Z","shell.execute_reply.started":"2023-08-10T20:10:29.988446Z","shell.execute_reply":"2023-08-10T20:10:32.747157Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","df = pd.DataFrame(results)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:10:18.028696Z","iopub.execute_input":"2023-08-10T20:10:18.029132Z","iopub.status.idle":"2023-08-10T20:10:18.037028Z","shell.execute_reply.started":"2023-08-10T20:10:18.029094Z","shell.execute_reply":"2023-08-10T20:10:18.035493Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["df.to_csv(f'random_chunk_{its}its.csv')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-08-10T20:10:35.746227Z","iopub.execute_input":"2023-08-10T20:10:35.746880Z","iopub.status.idle":"2023-08-10T20:10:35.754623Z","shell.execute_reply.started":"2023-08-10T20:10:35.746836Z","shell.execute_reply":"2023-08-10T20:10:35.753209Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}